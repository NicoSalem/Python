{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "## Predicting Rating from Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "vectoriser = CountVectorizer()\n",
    "\n",
    "import statsmodels.api as sms\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dear longman &amp; eagle.......you've left me no c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delish. The hubby and I wanted to do brunch on...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yep, I've giving Yolk 5 stars. It's just reall...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meat, meat, meat. It's meat-tastic. So much me...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I caught up with the law school girls on a Sat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  rating\n",
       "0  dear longman & eagle.......you've left me no c...       1\n",
       "1  Delish. The hubby and I wanted to do brunch on...       5\n",
       "2  yep, I've giving Yolk 5 stars. It's just reall...       5\n",
       "3  Meat, meat, meat. It's meat-tastic. So much me...       3\n",
       "4  I caught up with the law school girls on a Sat...       3"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv('review_meta_train.csv')\n",
    "d['review_text'] = pd.read_csv('review_text_train.csv')\n",
    "data = d[['review_text', 'rating']]\n",
    "del d\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    19288\n",
      "3     6444\n",
      "1     2336\n",
      "Name: rating, dtype: int64\n",
      "28068\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='rating', data=data)\n",
    "print(data['rating'].value_counts())\n",
    "print(data['rating'].count())\n",
    "zeror = 19288/28068"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data and processing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_50_test = pd.read_csv(r\"review_text_test_doc2vec50.csv\", index_col = False, delimiter = ',', header=None)\n",
    "data_200_test = pd.read_csv(r\"review_text_test_doc2vec200.csv\", index_col = False, delimiter = ',', header=None)\n",
    "\n",
    "data_50f = pd.read_csv(r\"review_text_train_doc2vec50.csv\", index_col = False, delimiter = ',', header=None)\n",
    "data_100f = pd.read_csv(r\"review_text_train_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "data_200f = pd.read_csv(r\"review_text_train_doc2vec200.csv\", index_col = False, delimiter = ',', header=None)\n",
    "\n",
    "x_train_txt = data['review_text']\n",
    "x = vectoriser.fit_transform(x_train_txt)\n",
    "y = data['rating']\n",
    "\n",
    "x_train50, x_test50, y_train50, y_test50 = train_test_split(data_50f, y, test_size=0.3, random_state=1)\n",
    "x_train100, x_test100, y_train100, y_test100 = train_test_split(data_100f, y, test_size=0.3, random_state=1)\n",
    "x_train200, x_test200, y_train200, y_test200 = train_test_split(data_200f, y, test_size=0.3, random_state=1)\n",
    "x_train_complete, x_test_complete, y_train_complete, y_test_complete = train_test_split(x, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_given_nostop = scipy.sparse.load_npz('review_text_train_vec.npz')\n",
    "x_train_nostop, x_test_nostop, y_train_nostop, ygiven_test_nostop = train_test_split(x_given_nostop, y, test_size=0.3, random_state=0)\n",
    "x_given_nostop_test = scipy.sparse.load_npz('review_text_test_vec.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse document frequency:\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer().fit(x_given_nostop)\n",
    "inversedoc_x = transformer.transform(x_given_nostop)\n",
    "x_train_inverse, x_test_inverse, y_train_inverse, y_test_inverse = train_test_split(inversedoc_x, y, test_size=0.3, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale Data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(data_50f)\n",
    "data_50s = scaler.transform(data_50f)\n",
    "x_train50s, x_test50s, y_train50s, y_test50s = train_test_split(data_50s, y, test_size=0.3, random_state=1)\n",
    "\n",
    "scaler.fit(data_100f)\n",
    "data_100s = scaler.transform(data_100f)\n",
    "x_train100s, x_test100s, y_train100s, y_test100s = train_test_split(data_100s, y, test_size=0.3, random_state=1)\n",
    "\n",
    "scaler.fit(data_200f)\n",
    "data_200s = scaler.transform(data_200f)\n",
    "x_train200s, x_test200s, y_train200s, y_test200s = train_test_split(data_200s, y, test_size=0.3, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = [(x_train50s, x_test50s, y_train50s, y_test50s), \n",
    "     (x_train100s, x_test100s, y_train100s, y_test100s), \n",
    "     (x_train200s, x_test200s, y_train200s, y_test200s),\n",
    "     (x_train_complete, x_test_complete, y_train_complete, y_test_complete),\n",
    "     (x_train_nostop, x_test_nostop, y_train_nostop, ygiven_test_nostop)]\n",
    "\n",
    "X_names = ['50 features', '100 features', '200 features', 'Complete', 'no-stop']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0R\t\t acc 0.6871882570899245 \n",
      "\n",
      "One-R\n",
      "50 features \t acc 0.6830542690891818\n",
      "100 features \t acc 0.6830542690891818\n",
      "200 features \t acc 0.6830542690891818\n",
      "Complete \t acc 0.6830542690891818\n",
      "no-stop \t acc 0.7001543759648498\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth=1)\n",
    "print('0R\\t\\t acc',zeror,'\\n')\n",
    "\n",
    "print('One-R')\n",
    "for X_name, X in zip(X_names, Xs):\n",
    "    X_train_t, X_test_t, y_train_t, y_test_t = X\n",
    "    model.fit(X_train_t, y_train_t)\n",
    "    acc = model.score(X_test_t, y_test_t)\n",
    "    print(X_name, '\\t acc',  acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB\n",
      "50 features \t acc 0.6830542690891818\n",
      "100 features \t acc 0.6830542690891818\n",
      "200 features \t acc 0.6830542690891818\n",
      "Complete \t acc 0.8399239995249971\n",
      "no-stop \t acc 0.8389739935874599\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "print('MNB')\n",
    "for X_name, X in zip(X_names, Xs):\n",
    "    X_train_t, X_test_t, y_train_t, y_test_t = X\n",
    "    model.fit(X_train_t, y_train_t)\n",
    "    acc = model.score(X_test_t, y_test_t)\n",
    "    print(X_name, '\\t acc',  acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB\n",
      "50 features\t acc 0.7223607647547797\n",
      "100 features\t acc 0.6677354233463959\n",
      "200 features\t acc 0.612160076000475\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "print('GNB')\n",
    "model.fit(x_train50s, y_train50s)\n",
    "acc = model.score(x_test50s, y_test50s)\n",
    "print('50 features\\t acc', acc)\n",
    "\n",
    "model.fit(x_train100s, y_train100s)\n",
    "acc = model.score(x_test100s, y_test100s)\n",
    "print('100 features\\t acc', acc)\n",
    "\n",
    "model.fit(x_train200s, y_train200s)\n",
    "acc = model.score(x_test200s, y_test200s)\n",
    "print('200 features\\t acc', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 nearest neighbour\n",
      "50 features \t acc 0.6967106044412777\n",
      "100 features \t acc 0.6836480228001425\n",
      "200 features \t acc 0.6680916755729723\n",
      "Complete \t acc 0.6787792423702648\n",
      "no-stop \t acc 0.6803230020187626\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "print('1 nearest neighbour')\n",
    "for X_name, X in zip(X_names, Xs):\n",
    "    X_train_t, X_test_t, y_train_t, y_test_t = X\n",
    "    model.fit(X_train_t, y_train_t)\n",
    "    acc = model.score(X_test_t, y_test_t)\n",
    "    print(X_name, '\\t acc',  acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 nearest neighbour\n",
      "50 features \t acc 0.7576297351858449\n",
      "100 features \t acc 0.7313858211613823\n",
      "200 features \t acc 0.6999168744804655\n",
      "Complete \t acc 0.7018168863555397\n",
      "no-stop \t acc 0.7025293908086926\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "print('5 nearest neighbour')\n",
    "for X_name, X in zip(X_names, Xs):\n",
    "    X_train_t, X_test_t, y_train_t, y_test_t = X\n",
    "    model.fit(X_train_t, y_train_t)\n",
    "    acc = model.score(X_test_t, y_test_t)\n",
    "    print(X_name, '\\t acc',  acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree\n",
      "50 features \t acc 0.644697779361121\n",
      "100 features \t acc 0.6260539128369552\n",
      "200 features \t acc 0.6132288326802042\n",
      "Complete \t acc 0.7030043937774612\n",
      "no-stop \t acc 0.7026481415508847\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth=None)\n",
    "print('decision tree')\n",
    "for X_name, X in zip(X_names, Xs):\n",
    "    X_train_t, X_test_t, y_train_t, y_test_t = X\n",
    "    model.fit(X_train_t, y_train_t)\n",
    "    acc = model.score(X_test_t, y_test_t)\n",
    "    print(X_name, '\\t acc',  acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "50 features \t acc 0.7918299489371808\n",
      "100 features \t acc 0.7877924237026481\n",
      "200 features \t acc 0.7590547440921506\n",
      "Complete \t acc 0.6830542690891818\n",
      "no-stop \t acc 0.6844792779954875\n"
     ]
    }
   ],
   "source": [
    "model = SVC(gamma='auto')\n",
    "print('SVM')\n",
    "for X_name, X in zip(X_names, Xs):\n",
    "    X_train_t, X_test_t, y_train_t, y_test_t = X\n",
    "    model.fit(X_train_t, y_train_t)\n",
    "    acc = model.score(X_test_t, y_test_t)\n",
    "    print(X_name, '\\t acc',  acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "50 features \t acc 0.8160551003443771\n",
      "100 features \t acc 0.822705141907137\n",
      "200 features \t acc 0.8316114475715474\n",
      "Complete \t acc 0.8536990856192851\n",
      "no-stop \t acc 0.842417765111032\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='auto', solver='lbfgs', max_iter=1000)\n",
    "print('Logistic Regression')\n",
    "for X_name, X in zip(X_names, Xs):\n",
    "    X_train_t, X_test_t, y_train_t, y_test_t = X\n",
    "    model.fit(X_train_t, y_train_t)\n",
    "    acc = model.score(X_test_t, y_test_t)\n",
    "    accuracies\n",
    "    print(X_name, '\\t acc',  acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bag-of-words vs TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "tfidf_pipeline = Pipeline([\n",
    "    ('vectorization', CountVectorizer(stop_words='english')),\n",
    "    ('inversedoc', TfidfTransformer()),\n",
    "    ('model', MultinomialNB())\n",
    "])\n",
    "\n",
    "bow_pipeline = Pipeline([\n",
    "    ('vectorization', CountVectorizer(stop_words='english')),\n",
    "    ('model', MultinomialNB())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words\t acc 0.8432490203063769\n",
      "Inverse doc\t acc 0.6973043581522385\n"
     ]
    }
   ],
   "source": [
    "x_train_inversedoc, x_test_inversedoc, y_train_inversedoc, y_test_inversedoc = train_test_split(data['review_text'], data['rating'], test_size=0.3)\n",
    "\n",
    "bow_pipeline.fit(x_train_inversedoc, y_train_inversedoc)\n",
    "acc = bow_pipeline.score(x_test_inversedoc, y_test_inversedoc)\n",
    "print('bag of words\\t acc', acc)\n",
    "\n",
    "tfidf_pipeline.fit(x_train_inversedoc, y_train_inversedoc)\n",
    "acc = tfidf_pipeline.score(x_test_inversedoc, y_test_inversedoc)\n",
    "print('Inverse doc\\t acc', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interesting to note that MNB performed better with bag-of-words than with TF_IDF\n",
    "perhaps this is because TF_IDF was not agood approach to grouping similar types of reviews\n",
    "and ended up reducing the weight of important but frequent words such as 'good' present in many postive reviews\n",
    "resulting in loss of important imformation\n",
    "not mentioned in the repoort due to lack of space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(gamma=1, C=1, kernel='rbf')\n",
    "print('SVM')\n",
    "for X_name, X in zip(X_names, Xs):\n",
    "    X_train_t, X_test_t, y_train_t, y_test_t = X\n",
    "    model.fit(X_train_t, y_train_t)\n",
    "    acc = model.score(X_test_t, y_test_t)\n",
    "    print(X_name, '\\t acc',  acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(gamma=1, C=1, kernel='poly', degree=2)\n",
    "print('SVM')\n",
    "for X_name, X in zip(X_names, Xs):\n",
    "    X_train_t, X_test_t, y_train_t, y_test_t = X\n",
    "    model.fit(X_train_t, y_train_t)\n",
    "    acc = model.score(X_test_t, y_test_t)\n",
    "    print(X_name, '\\t acc',  acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM needs the best combination of parameters:\n",
    "print('Tuned SVM')\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C':[0.1,1,10,100,1000], 'gamma':[1,0.1,0.01,0.001,0.0001]}\n",
    "grid = GridSearchCV(SVC(), param_grid)\n",
    "grid.fit(x_train50s, y_train50s)\n",
    "acc = grid.score(x_test50s, y_test50s)\n",
    "print(grid.best_params_)\n",
    "print('50 features\\t acc', acc)\n",
    "\n",
    "grid.fit(x_train100s, y_train100s)\n",
    "acc = grid.score(x_test100s, y_test100s)\n",
    "print('100 features\\t acc', acc)\n",
    "\n",
    "grid.fit(x_train200s, y_train200s)\n",
    "acc = grid.score(x_test200s, y_test200s)\n",
    "print('200 features\\t acc', acc)\n",
    "\n",
    "grid.fit(x_train_complete, y_train200_complete)\n",
    "acc = grid.score(x_test200s, y_test200s)\n",
    "print('bow \\t\\t acc', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Predictions based on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg\n",
      "7018\n",
      "   instance_id  rating\n",
      "0            1       5\n",
      "1            2       5\n",
      "2            3       1\n",
      "3            4       3\n",
      "4            5       5\n",
      "      instance_id  rating\n",
      "7013         7014       5\n",
      "7014         7015       5\n",
      "7015         7016       1\n",
      "7016         7017       5\n",
      "7017         7018       5\n"
     ]
    }
   ],
   "source": [
    "d_test_set = pd.read_csv('review_text_test.csv')\n",
    "x_test_set = vectoriser.fit_transform(d_test_set['review'])\n",
    "\n",
    "model = LogisticRegression(multi_class='auto', solver='lbfgs', max_iter=1000)\n",
    "print('logreg')\n",
    "# model.fit(x_train50s, y_train50s)\n",
    "# acc = model.score(x_test50s, y_test50s)\n",
    "# print('50 features\\t acc', acc)\n",
    "\n",
    "# model.fit(x_train100s, y_train100s)\n",
    "# acc = model.score(x_test100s, y_test100s)\n",
    "# print('100 features\\t acc', acc)\n",
    "\n",
    "# model.fit(x_train200s, y_train200s)\n",
    "# acc = model.score(x_test200s, y_test200s)\n",
    "# print('200 features\\t acc', acc)\n",
    "\n",
    "# model.fit(x_train_complete, y_train_complete)\n",
    "# acc = model.score(x_test_complete, y_test_complete)\n",
    "# print('Complete\\t acc', acc)\n",
    "    \n",
    "model.fit(x_train200s, y_train200s)\n",
    "p = model.predict(data_200_test)\n",
    "print(len(p))\n",
    "final_predictions = pd.DataFrame()\n",
    "final_predictions['instance_id'] = range(1,len(p)+1)\n",
    "final_predictions['rating'] = p\n",
    "print(final_predictions.head())\n",
    "print(final_predictions.tail())\n",
    "final_predictions.to_csv('final_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy matrix based on multple previous runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>50f</th>\n",
       "      <th>100f</th>\n",
       "      <th>200f</th>\n",
       "      <th>complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0R</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1R</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNB</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GNB</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.612</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1NN</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5NN</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tree</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tuned SVM</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model    50f   100f   200f complete\n",
       "0         0R  0.687  0.687  0.687    0.687\n",
       "1         1R  0.684  0.684  0.684    0.684\n",
       "2        MNB  0.683  0.683  0.683    0.842\n",
       "3        GNB  0.722  0.668  0.612        -\n",
       "4        1NN  0.693  0.693  0.671    0.671\n",
       "5        5NN  0.756  0.735  0.705    0.714\n",
       "6       Tree  0.647  0.632  0.610    0.705\n",
       "7        SVM  0.801  0.796  0.762    0.685\n",
       "8  Tuned SVM  0.833  0.805  0.793    0.686\n",
       "9     LogReg  0.818  0.829  0.835    0.861"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = pd.DataFrame(columns=('model','50f','100f','200f','complete'))\n",
    "accuracies = accuracies.append({'model':'0R', '50f':0.687, '100f':0.687, '200f':0.687, 'complete':0.687}, ignore_index=True)\n",
    "accuracies = accuracies.append({'model':'1R', '50f':0.684, '100f':0.684, '200f':0.684, 'complete':0.684}, ignore_index=True)\n",
    "accuracies = accuracies.append({'model':'MNB', '50f':0.683, '100f':0.683, '200f':0.683, 'complete':0.842}, ignore_index=True)\n",
    "accuracies = accuracies.append({'model':'GNB', '50f':0.722, '100f':0.668, '200f':0.612, 'complete':'-'}, ignore_index=True)\n",
    "accuracies = accuracies.append({'model':'1NN', '50f':0.693, '100f':0.693, '200f':0.671, 'complete':0.671}, ignore_index=True)\n",
    "accuracies = accuracies.append({'model':'5NN', '50f':0.756, '100f':0.735, '200f':0.705, 'complete':0.714}, ignore_index=True)\n",
    "accuracies = accuracies.append({'model':'Tree', '50f':0.647, '100f':0.632, '200f':0.610, 'complete':0.705}, ignore_index=True)\n",
    "accuracies = accuracies.append({'model':'SVM', '50f':0.801, '100f':0.796, '200f':0.762, 'complete':0.685}, ignore_index=True)\n",
    "accuracies = accuracies.append({'model':'Tuned SVM', '50f':0.833, '100f':0.805, '200f':0.793, 'complete':0.686}, ignore_index=True)\n",
    "accuracies = accuracies.append({'model':'LogReg', '50f':0.818, '100f':0.829, '200f':0.835, 'complete':0.861}, ignore_index=True)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### supporting info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence:  ['machine learning and natural natural language processing with python ']\n",
      "bag of words:\n",
      "   (0, 2138)\t1\n",
      "  (0, 21249)\t1\n",
      "  (0, 21463)\t1\n",
      "  (0, 22469)\t1\n",
      "  (0, 24862)\t2\n",
      "  (0, 29142)\t1\n",
      "  (0, 29670)\t1\n",
      "  (0, 41142)\t1\n"
     ]
    }
   ],
   "source": [
    "string = ['machine learning and natural natural language processing with python ']\n",
    "print('sentence: ',string)\n",
    "print('bag of words:\\n',vectoriser.transform(string))\n",
    "# print('inverse document: ',transformer.transform(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [DecisionTreeClassifier(max_depth=1),\n",
    "            MultinomialNB(),\n",
    "            KNeighborsClassifier(n_neighbors=1),\n",
    "            KNeighborsClassifier(n_neighbors=5),\n",
    "            DecisionTreeClassifier(max_depth=None),\n",
    "            SVC(gamma='auto'),\n",
    "            LogisticRegression(multi_class='auto', solver='lbfgs', max_iter=1000)]\n",
    "\n",
    "titles = ['one-r',\n",
    "          'MNB',\n",
    "          '1-nearest neighbour',\n",
    "          '5-nearest neighbour',\n",
    "          'Decision Tree',\n",
    "          'SVM',\n",
    "          'Logistic Regression']\n",
    "\n",
    "print('0R\\n',zeror)\n",
    "for title, model in zip(titles, models):\n",
    "    print('\\n',title)\n",
    "    for X_name, X in zip(X_names, Xs):\n",
    "        X_train_t, X_test_t, y_train_t, y_test_t = X\n",
    "        model.fit(X_train_t, y_train_t)\n",
    "        acc = model.score(X_test_t, y_test_t)\n",
    "        print(X_name, '\\t acc',  acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB\n",
      "Complete\t acc 0.8399239995249971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.56      0.64       724\n",
      "           3       0.70      0.64      0.67      1945\n",
      "           5       0.89      0.94      0.91      5752\n",
      "\n",
      "    accuracy                           0.84      8421\n",
      "   macro avg       0.78      0.71      0.74      8421\n",
      "weighted avg       0.83      0.84      0.83      8421\n",
      "\n",
      "no stop\t\t acc 0.829592684954281\n"
     ]
    }
   ],
   "source": [
    "dx = scipy.sparse.load_npz('review_text_train_vec.npz')\n",
    "dxt = scipy.sparse.load_npz('review_text_test_vec.npz')\n",
    "dx_train_complete, dx_test_complete, dy_train_complete, dy_test_complete = train_test_split(dx, y, test_size=0.3, random_state=1)\n",
    "\n",
    "model = MultinomialNB()\n",
    "print('MNB')\n",
    "# model.fit(x_train50s, y_train50s)\n",
    "# acc = model.score(x_test50s, y_test50s)\n",
    "# print('50 features\\t acc', acc)\n",
    "\n",
    "# model.fit(x_train100s, y_train100s)\n",
    "# acc = model.score(x_test100s, y_test100s)\n",
    "# print('100 features\\t acc', acc)\n",
    "\n",
    "# model.fit(x_train200s, y_train200s)\n",
    "# acc = model.score(x_test200s, y_test200s)\n",
    "# print('200 features\\t acc', acc)\n",
    "\n",
    "model.fit(x_train_complete, y_train_complete)\n",
    "p = model.predict(x_test_complete)\n",
    "acc = model.score(x_test_complete, y_test_complete)\n",
    "print('Complete\\t acc', acc)\n",
    "print(classification_report(y_test_complete, p))\n",
    "\n",
    "model.fit(dx_train_complete, dy_train_complete)\n",
    "acc = model.score(dx_test_complete, dy_test_complete)\n",
    "print('no stop\\t\\t acc', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree\n",
      "50 features \t acc 1.0\n",
      "100 features \t acc 1.0\n",
      "200 features \t acc 1.0\n",
      "Complete \t acc 1.0\n",
      "no-stop \t acc 1.0\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth=None)\n",
    "print('decision tree')\n",
    "for X_name, X in zip(X_names, Xs):\n",
    "    X_train_t, X_test_t, y_train_t, y_test_t = X\n",
    "    model.fit(X_train_t, y_train_t)\n",
    "    acc = model.score(X_train_t, y_train_t)\n",
    "    print(X_name, '\\t acc',  acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words\t acc 0.8342239638997744\n",
      "Inverse doc\t acc 0.845861536634604\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-R\n",
      "Complete\t acc 0.6830542690891818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       724\n",
      "           3       0.00      0.00      0.00      1945\n",
      "           5       0.68      1.00      0.81      5752\n",
      "\n",
      "    accuracy                           0.68      8421\n",
      "   macro avg       0.23      0.33      0.27      8421\n",
      "weighted avg       0.47      0.68      0.55      8421\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nico\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "print('One-R')\n",
    "model.fit(x_train_complete, y_train_complete)\n",
    "p = model.predict(x_test_complete)\n",
    "acc = model.score(x_test_complete, y_test_complete)\n",
    "print('Complete\\t acc', acc)\n",
    "print(classification_report(y_test_complete, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
