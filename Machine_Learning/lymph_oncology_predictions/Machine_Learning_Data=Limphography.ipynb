{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Naive bayes classifier - Limpography data set\n",
    "\n",
    "### Testing different parameters on the laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt;\n",
    "import seaborn as sns \n",
    "import sklearn \n",
    "%matplotlib inline\n",
    "\n",
    "import scipy as sc \n",
    "import statsmodels.api as sm\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load and preprocess data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full data head(2): \n",
      "    0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18\n",
      "0   3   4   2   1   1   1   1   1   2   1   2   2   2   4   8   1   1   2   2\n",
      "1   2   3   2   1   1   2   2   1   2   1   3   3   2   3   4   2   2   2   2\n",
      "x head(2): \n",
      "    1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18\n",
      "0   4   2   1   1   1   1   1   2   1   2   2   2   4   8   1   1   2   2\n",
      "1   3   2   1   1   2   2   1   2   1   3   3   2   3   4   2   2   2   2\n",
      "y[0:2]: \n",
      " 2\n"
     ]
    }
   ],
   "source": [
    "x = pd.read_csv('datasets/lymphography.data', header=None)\n",
    "y = x[0]\n",
    "y = y.tolist()\n",
    "print(\"full data head(2): \\n {}\".format(x.head(2)))\n",
    "x.drop(x.columns[0], 1, inplace=True)\n",
    "\n",
    "print(\"x head(2): \\n {}\".format(x.head(2)))\n",
    "print(\"y[0:2]: \\n {}\".format(y[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18\n",
      "11    4   2   1   1   1   2   1   1   1   3   3   4   3   8   3   2   2   2\n",
      "127   2   2   1   1   1   2   1   2   1   2   2   3   3   4   2   1   2   1\n",
      "[2, 2]\n",
      "     1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18\n",
      "51    3   2   1   1   1   2   1   2   1   2   2   2   4   8   3   1   2   3\n",
      "124   4   2   1   1   1   2   1   1   1   2   2   3   3   5   2   1   2   1\n",
      "[3, 2]\n",
      "{1, 2, 3, 4}\n"
     ]
    }
   ],
   "source": [
    "# i.a) Split data:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "\n",
    "print(x_train.head(2))\n",
    "print(y_train[0:2])\n",
    "\n",
    "print(x_test.head(2))\n",
    "print(y_test[0:2])\n",
    "\n",
    "print(set(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 81, 3: 61, 4: 4, 1: 2})\n",
      "81\n",
      "61\n",
      "4\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# b) training discretized \n",
    "\n",
    "#i) compute priors:\n",
    "label_counter = Counter(y)\n",
    "print(label_counter)\n",
    "\n",
    "metastases, malign_lymph, fibrosis, normal_find = label_counter.most_common()\n",
    "\n",
    "n_meta = metastases[1]\n",
    "n_malign = malign_lymph[1]\n",
    "n_fib = fibrosis[1]\n",
    "n_normal = normal_find[1]\n",
    "\n",
    "print(n_metastases)\n",
    "print(n_malign_lymph)\n",
    "print(n_fibrosis)\n",
    "print(n_normal_find)\n",
    "\n",
    "\n",
    "p_meta = metastases[1]/(metastases[1]+malign_lymph[1]+fibrosis[1]+normal_find[1])\n",
    "p_malign = malign_lymph[1]/(metastases[1]+malign_lymph[1]+fibrosis[1]+normal_find[1])\n",
    "p_fib = fibrosis[1]/(metastases[1]+malign_lymph[1]+fibrosis[1]+normal_find[1])\n",
    "p_normal = normal_find[1]/(metastases[1]+malign_lymph[1]+fibrosis[1]+normal_find[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ii) compute conditional probailities with laplace smoothing \n",
    "\n",
    "# a) make data structure\n",
    "bayes_p = []\n",
    "bayes_p_e = []\n",
    "\n",
    "def make_dataStructure(bayes_p,s):\n",
    "    for att_n in x_train:\n",
    "        d = {}\n",
    "        d2 = {}\n",
    "        d3 = {}\n",
    "        d4 = {}\n",
    "        for att in set(x_train[att_n]):\n",
    "            d.update({att:s})\n",
    "            d2.update({att:s})\n",
    "            d3.update({att:s})\n",
    "            d4.update({att:s})\n",
    "        bayes_p.append({\"1\":d, \"2\":d2, \"3\":d3, \"4\":d4})\n",
    "        \n",
    "make_dataStructure(bayes_p,0)\n",
    "make_dataStructure(bayes_p_e,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {1: 0, 2: 0, 3: 0, 4: 0}, '2': {1: 0, 2: 0, 3: 0, 4: 0}, '3': {1: 0, 2: 0, 3: 0, 4: 0}, '4': {1: 0, 2: 0, 3: 0, 4: 0}}\n",
      "{'1': {1: 0, 2: 0, 3: 0, 4: 0}, '2': {1: 0, 2: 0, 3: 0, 4: 0}, '3': {1: 0, 2: 0, 3: 0, 4: 0}, '4': {1: 0, 2: 0, 3: 0, 4: 0}}\n"
     ]
    }
   ],
   "source": [
    "print(bayes_p[0])\n",
    "print(bayes_p_e[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) count to get probabilities\n",
    "\n",
    "def count(bayes_p):\n",
    "    for column_n in range(len(x_train.columns)): #every column\n",
    "        n = 0\n",
    "        for att in x_train[column_n+1]:            #every row\n",
    "            bayes_p[column_n][str(y_train[n])][att]+=1\n",
    "            n+=1\n",
    "count(bayes_p)\n",
    "count(bayes_p_e)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {1: 2, 2: 0, 3: 0, 4: 0}, '2': {1: 0, 2: 35, 3: 24, 4: 13}, '3': {1: 0, 2: 27, 3: 13, 4: 15}, '4': {1: 0, 2: 0, 3: 4, 4: 0}}\n",
      "{'1': {1: 2, 2: 0, 3: 0, 4: 0}, '2': {1: 0, 2: 35, 3: 24, 4: 13}, '3': {1: 0, 2: 27, 3: 13, 4: 15}, '4': {1: 0, 2: 0, 3: 4, 4: 0}}\n",
      "Counter({2: 62, 3: 41, 4: 28, 1: 2})\n"
     ]
    }
   ],
   "source": [
    "print(bayes_p[0])\n",
    "print(bayes_p_e[0])\n",
    "\n",
    "label_counter = Counter(x_train[1])\n",
    "print(label_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_train.head(2))\n",
    "# print(range(len(x_train.columns)))\n",
    "# for i in range(len(x_train.columns)):\n",
    "#     print(x_train[i+1].head(2))\n",
    "#     print(set(x_train[i+1]))\n",
    "#     print(bayes_p[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['3', '2', '2', '2', '2', '3', '2', '3', '3', '2']\n",
      "['3', '2', '2', '2', '2', '3', '3', '3', '3', '2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nico\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Nico\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Nico\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "predictions_addk = []\n",
    "predictions_e = []\n",
    "\n",
    "print(predictions_addk[0:10])\n",
    "print(predictions_e[0:10])\n",
    "\n",
    "def predict(test_dataStructure, pred_list,e, smth, k):\n",
    "    for instance in x_test.iterrows():\n",
    "        column_n = 0\n",
    "        instance_p_meta = np.log(p_meta)\n",
    "        instance_p_malign = np.log(p_malign)\n",
    "        instance_p_fib = np.log(p_fib)\n",
    "        instance_p_normal = np.log(p_normal)\n",
    "        li = []\n",
    "\n",
    "        for att in instance[1]:\n",
    "            if smth=='addk':\n",
    "                mt = test_dataStructure[column_n]['2'][att] \n",
    "                ml = test_dataStructure[column_n]['3'][att]\n",
    "                fb = test_dataStructure[column_n]['4'][att]\n",
    "                n = test_dataStructure[column_n]['1'][att]\n",
    "                pmt = (mt+k)/(n_meta+k*len(set(test_dataStructure[column_n]['2'])))\n",
    "                pml = (ml+k)/(n_malign+k*len(set(test_dataStructure[column_n]['3'])))\n",
    "                pfb = (fb+k)/(n_fib+(k*len(set(test_dataStructure[column_n]['4']))))\n",
    "                pn = (n+k)/(n_normal+k*len(set(test_dataStructure[column_n]['1'])))\n",
    "            else:\n",
    "                try:\n",
    "                    mt = test_dataStructure[column_n]['2'][att] \n",
    "                    ml = test_dataStructure[column_n]['3'][att]\n",
    "                    fb = test_dataStructure[column_n]['4'][att]\n",
    "                    n = test_dataStructure[column_n]['1'][att]\n",
    "                    pmt = mt/n_meta\n",
    "                    pml = ml/n_malign\n",
    "                    pfb = fb/n_fib\n",
    "                    pn = n/n_normal\n",
    "                except:\n",
    "                    pmt = e\n",
    "                    pml = e\n",
    "                    pfb = e\n",
    "                    pn = e           \n",
    "\n",
    "            instance_p_meta += np.log(pmt)\n",
    "            instance_p_malign += np.log(pml)\n",
    "            instance_p_fib += np.log(pfb)\n",
    "            instance_p_normal += np.log(pn)\n",
    "\n",
    "            column_n+=1\n",
    "\n",
    "        li.append(instance_p_meta)\n",
    "        li.append(instance_p_malign)\n",
    "        li.append(instance_p_fib)\n",
    "        li.append(instance_p_normal)\n",
    "\n",
    "        if instance_p_meta==max(li):\n",
    "            pred_list.append('2')\n",
    "        elif instance_p_malign==max(li):\n",
    "            pred_list.append('3')\n",
    "        elif instance_p_fib==max(li):\n",
    "            pred_list.append('4')\n",
    "        elif instance_p_normal==max(li):\n",
    "            pred_list.append('1')\n",
    "            \n",
    "predict(bayes_p, predictions_addk, 2,'addk',2)\n",
    "predict(bayes_p_e, predictions_e, 0.00001,'e',0)\n",
    "#note: the values of the 3,4 and 5th params depend on the version of smoothing and may be irrelevant\n",
    "\n",
    "print(predictions_addk[0:10])\n",
    "print(predictions_e[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "0R's accuracy: 0.4666666666666667\n",
      "12\n",
      "model's accuracy: 0.8\n",
      "11\n",
      "model's accuracy: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy and compare with 0R's accuracy\n",
    "\n",
    "# make 0R and calculate accuracy\n",
    "y_test = list(map(str, y_test))\n",
    "zero_r = []\n",
    "for i in y_test:\n",
    "    zero_r.append('2')\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(zero_r)):\n",
    "    if zero_r[i]==y_test[i]: correct+=1\n",
    "print(correct)\n",
    "    \n",
    "accuracy_zero_r = correct/(len(y_test))\n",
    "print(\"0R's accuracy: {}\" .format(accuracy_zero_r))\n",
    "\n",
    "#calculate predictions accuracy\n",
    "\n",
    "def accuracy(p):\n",
    "    correct = 0\n",
    "    for i in range(len(p)):\n",
    "        if p[i]==y_test[i]: correct+=1 \n",
    "    print(correct)\n",
    "    accuracy = correct/(len(y_test))\n",
    "    print(\"model's accuracy: {}\" .format(accuracy))\n",
    "    \n",
    "accuracy(predictions_addk)\n",
    "accuracy(predictions_e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for instance in x_test.iterrows():\n",
    "#     column_n = 0\n",
    "#     for att in instance[1]:\n",
    "#         print(\"att: {}\".format(att))\n",
    "#         print(\"bayes_p[{}]: {}\".format(column_n,bayes_p[column_n]))\n",
    "#         print(\"bayes_p[{}]['2']: {}\".format(column_n,bayes_p[column_n]['2']))\n",
    "#         print(\"bayes_p[{}]['2'][{}]: {}\\n\".format(column_n,att,bayes_p[column_n]['2'][att]))\n",
    "#         column_n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "print(bayes_p[0]['2'][2])\n",
    "print(bayes_p_e[0]['2'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
